{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer, one_hot, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Embedding, Bidirectional, LSTM, Flatten, Dropout, Input, Conv1D, MaxPooling1D\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Dense, Input, Flatten, Reshape, concatenate, Dropout\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Embedding\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Convolution1D, Flatten, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "# Using keras to load the dataset with the top_words\n",
    "top_words = 10000\n",
    "max_review_length = 900\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[1:2000,]\n",
    "y_train = y_train[1:2000,]\n",
    "\n",
    "X_test = X_test[1:500,]\n",
    "y_test = y_test[1:500,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.7127 - acc: 0.5253\n",
      "Epoch 2/3\n",
      "1999/1999 [==============================] - 1s 363us/step - loss: 0.2234 - acc: 0.9080\n",
      "Epoch 3/3\n",
      "1999/1999 [==============================] - 1s 366us/step - loss: 0.0159 - acc: 0.9985\n",
      "DeepExplain: running \"elrp\" explanation method (4)\n",
      "Model with multiple inputs:  False\n",
      "attributions shape --- (499, 900, 300)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "from deepexplain.tensorflow import DeepExplain\n",
    "from keras.layers import Activation\n",
    "from keras import backend as K\n",
    "max_review_length = 900\n",
    "current_session = K.get_session() \n",
    "\n",
    "with DeepExplain(session=current_session) as de:  # <-- init DeepExplain context\n",
    "    from numpy.random import seed\n",
    "    seed(1)\n",
    "    from tensorflow import set_random_seed\n",
    "    set_random_seed(2)\n",
    "    embedding_vecor_length = 300\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "    model.add(Convolution1D(64, 3, padding='same'))\n",
    "    model.add(Convolution1D(32, 3, padding='same'))\n",
    "    model.add(Convolution1D(16, 3, padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(180,activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=3)    \n",
    "\n",
    "\n",
    "   # predict on test data\n",
    "    y_pred = model.predict(np.array(X_test));\n",
    "    y_test = np.array(y_test);\n",
    "    \n",
    "    # Evaluate the embedding tensor on the model input (in other words, perform the lookup)\n",
    "    embedding_tensor = model.layers[0].output\n",
    "    input_tensor = model.inputs[0]\n",
    "    embedding_out = current_session.run(embedding_tensor, {input_tensor: X_test});\n",
    "\n",
    "    xs = X_test;\n",
    "    ys = y_test;\n",
    "    # Run DeepExplain with the embedding as input\n",
    "    attributions = de.explain('elrp', model.layers[-1].output * ys, model.layers[1].input, embedding_out);\n",
    "    print(\"attributions shape --- {}\".format(attributions.shape));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####Sums the attributions since the original attributions are in the context of word embeddings (499, 900, 300) --> (499,900)\n",
    "import numpy as np \n",
    "sum_attributions = np.sum(attributions, -1)\n",
    "sum_attributions[11].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          1,   40,   49,   85,   84, 1040,  146,    6,  783,  254, 4386,\n",
       "        337,    5,   13,  447,   14,  500,   10,   10,   14,  500,  517,\n",
       "       1076,  357,   21, 1684,   72,   45,  290,   12,   17,  515,   17,\n",
       "         25,  380,  129, 3305,    4, 2191,   26,  253,    5,    2,   36,\n",
       "         80, 4357,   25,    2,  129,  330,  505,    8,    2,  146,   24,\n",
       "       3988,   14,  500,    9,   82,    2,    5,    9, 1293,  224,   10,\n",
       "         10,    8,  401,   14, 1361,  879,   13,   28,    8,  401,   61,\n",
       "       1642, 2925,   44, 1373,   21,  591,  353,   14,  500, 4092,   30,\n",
       "        290,   12,   10,   10,   65,  790,  790,  206,  158,  300,   45,\n",
       "         15,   52,    2,  158,  692,    2,  158,  856,  158], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "###attribution shape corresponds to max review length \n",
    "first_all_test = sum_attributions[3]\n",
    "first_all_test.shape\n",
    "\n",
    "a = first_all_test\n",
    "s = int(np.sqrt(first_all_test.size))\n",
    "b = first_all_test.reshape(s, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEj1JREFUeJzt3W+MHdV5x/HfY68BhwXFziauC8YmlFaltJhqSyoFVa5QI4IqAVJlxW0jt0UxL4IUVKKCqFR40xa1gTQvKhpTaExLaJDAwa1QG2pRuVFUmoU4tsHlb5dia7HZOAGv4wLeffriDoet2XPO+J47d2bp9yMh351zz8xz5+4+zL3POWfM3QUAkrSk7QAAdAcJAUBAQgAQkBAABCQEAAEJAUDQSkIwsyvN7Dkze9HMbmkjhpOZ2aSZ7TWz3WY20WIc95nZYTPbN2/bSjN73MxeqP5d0YGYbjezg9X52m1mVw05pjVm9oSZPWtmz5jZF6rtrZ2rREytnqtTYcMeh2BmSyU9L+nXJB2Q9F1Jm9z92aEG8v64JiWNu/t0y3H8iqQZSfe7+8XVtj+TdMTd76gS6Ap3v7nlmG6XNOPuXxpWHCfFtFrSand/2szOkvSUpGsk/Y5aOleJmDaqxXN1Ktq4QrhM0ovu/rK7vy3p7yVd3UIcneTuuyQdOWnz1ZK2VY+3qfdL1nZMrXL3KXd/unp8VNJ+SeeoxXOViGnRaCMhnCPp1Xk/H1A3TppL+paZPWVmW9oO5iSr3H2qevyapFVtBjPPDWa2p/pIMdSPMfOZ2TpJl0p6Uh05VyfFJHXkXOXwpeJ7Lnf3X5T0aUmfry6TO8d7n/G6MN78bkkXSFovaUrSnW0EYWajkh6WdKO7vzm/ra1ztUBMnThXdbSREA5KWjPv53Orba1y94PVv4clbVfvo01XHKo+n777OfVwy/HI3Q+5+6y7z0m6Ry2cLzNbpt4f3gPu/ki1udVztVBMXThXdbWREL4r6UIzO9/MTpP0GUk7WogjMLMzqy+BZGZnSvqUpH3pXkO1Q9Lm6vFmSY+2GIuk8Mf2rms15PNlZibpXkn73f2ueU2tnatYTG2fq1Mx9CqDJFVll7+QtFTSfe7+x0MP4v/G83H1rgokaUTS19uKycwelLRB0pikQ5Juk/RNSQ9JOk/SK5I2uvvQvuSLxLRBvUtglzQp6fp5n92HEdPlkv5N0l5Jc9XmW9X7zN7KuUrEtEktnqtT0UpCANBNfKkIICAhAAhICAACEgKAgIQAIGg1IXRwiDAx1URM9XU1roW0fYXQxRNFTPUQU31djet92k4IADqkaGCSmV0p6SvqjTj8a3e/I/X8sdHlvnbl2eHn6ZnjGhtd3vfxQxyyZLufwvyWQcUkpeMqiWmQr7dfpxpTyqDiHeR7N0jDfP9i+5488oamZ45n36SRvg/cW+jkLzVvoRMz25Fa6GTtyrP15Bd/q99DpmJJtrc1GjMVV2EiTra3NBy9774+N5d+QsG+u6jJ9y+270/8+QO1+pd8ZGChE+ADpiQhdHWhEwB9avxLRTPbYmYTZjYxPXO86cMBKFCSEGotdOLuW9193N3Hu/iFD4D39P2louYtdKJeIviMpN8cSFSnqKtTuJuKq2i/ub6JL7ya+pI0+6VhYt+2JP3/tKa+vC3Zb5O/r7F9161c9J0Q3P2Emd0g6Z/13kInz/S7PwDtK7lCkLs/JumxAcUCoGWMVAQQkBAABCQEAAEJAUBAQgAQFFUZ0JKCsQQlE4WSk5CanIDU1PiHkvNYsu/MfovGPxSOceAKAUBAQgAQkBAABCQEAAEJAUBAQgAQDLXsaLJoSaWrU5ibUrSuXpNlq/SO+zpm8XELJM9Fpm/R1OnEtOzcflPtTZ9nrhAABCQEAAEJAUBAQgAQkBAABCQEAAEJAUAw1HEILv9AjTcoqQkvxvOQrOm3dH/Gro5/aEr29RSeZ64QAAQkBAABCQFAQEIAEJAQAAQkBADBB2LV5SZLT41NJW5QK3EVlLuaLN82toLxB7TcWZQQzGxS0lFJs5JOuPv4IIIC0I5BXCH8qrtPD2A/AFrGdwgAgtKE4JK+ZWZPmdmWQQQEoD2lHxkud/eDZvYxSY+b2X+6+675T6gSxRZJOm/FWYWHA9CkoisEdz9Y/XtY0nZJly3wnK3uPu7u42Ojy0sOB6BhfScEMzvTzM5697GkT0naN6jAAAxfyUeGVZK2V3XeEUlfd/d/yvaK1WdL7krcYC26k8uHtxRTU8dt8vU0tex8yZ2juzxlu++E4O4vS7pkgLEAaBllRwABCQFAQEIAEJAQAAQkBADB8Kc/R0ouTZZiOjkVteHVc9GwBsvkJWJ/R6Z68XKFACAgIQAISAgAAhICgICEACAgIQAISAgAgs4sw15Um12MNf0uxlSApfC7IXY+XPXOE1cIAAISAoCAhAAgICEACEgIAAISAoCgM2XHIrkSXqI0ZUvSOTFZ1sqt9pzY92Isl7VV/luM56pEm2VWrhAABCQEAAEJAUBAQgAQkBAABCQEAAEJAUCQHYdgZvdJ+nVJh9394mrbSknfkLRO0qSkje7+w5JAGr0jbkFdN1kTzhy2raXj/z9NFy75venqXZjbfI/qXCF8TdKVJ227RdJOd79Q0s7qZwCLXDYhuPsuSUdO2ny1pG3V422SrhlwXABa0O93CKvcfap6/JqkVQOKB0CLir9U9N4HnuiHHjPbYmYTZjYxPXO89HAAGtRvQjhkZqslqfr3cOyJ7r7V3cfdfXxsdHmfhwMwDP0mhB2SNlePN0t6dDDhAGhTnbLjg5I2SBozswOSbpN0h6SHzOw6Sa9I2thkkG1ajOW/xRZzSfnP5+bS+25oCnpr5c4+p9zXvftzNiG4+6ZI0xW1jgBg0WCkIoCAhAAgICEACEgIAAISAoCAhAAgGOoy7CaL1mBz9eTUFOYP4hTYlCbr2KnWkjEKReMbCpbR73e/vZ03c4fupqbyp/bN3Z8BnDISAoCAhAAgICEACEgIAAISAoCgM3d/zt6FOVGWzBVUkiWvlsqdWakpv5muJStFp7S1inRJ+a+1snFTdxzPiL33dac/c4UAICAhAAhICAACEgKAgIQAICAhAAhICACCoY5DcHm0xpqr6TdViy6pCTda427q9XZxunefS4v3uvY/dbrR8Q2L9A7cXCEACEgIAAISAoCAhAAgICEACEgIAILhT3+OlVwaWuG2WEHZqmTaddFqwglNTckuOhcNluGauvtz9rgtvfeNr7psZveZ2WEz2zdv2+1mdtDMdlf/XVU3YADdVScVfU3SlQts/7K7r6/+e2ywYQFoQzYhuPsuSUeGEAuAlpV8UL3BzPZUHylWxJ5kZlvMbMLMJqZnjhccDkDT+k0Id0u6QNJ6SVOS7ow90d23uvu4u4+PjS7v83AAhqGvhODuh9x91t3nJN0j6bLBhgWgDX2VHc1stbtPVT9eK2lf6vkndV5wc6M3C03IHregbJVsz806TJSmSspSRbMdmyoNtzQDM3suCt6D1laoLpRNCGb2oKQNksbM7ICk2yRtMLP16q3qPSnp+gZjBDAk2YTg7psW2HxvA7EAaBlDlwEEJAQAAQkBQEBCABCQEAAEQ53+bLJo7beopl+gk6sQS7KR+Fvjs7Ppzqn6+dKl6eP2OdYgexftxHEt0ze574L3L/dam1rtuckxDKW4QgAQkBAABCQEAAEJAUBAQgAQkBAABJ252StOkivjJaRKi42t+Jsr/5040XffVHtbZePscVNtTa72HHnvTfXKyVwhAAhICAACEgKAgIQAICAhAAhICAACEgKAYPh3f45pcDn0krsWt6WoVp0aS9DWNPPU+5cbc9HSe1QydTo5jiQ37XrZsnhM77zT/3Fr4AoBQEBCABCQEAAEJAQAAQkBQEBCABB0p+xYUlrKTelNTQcuWT03sTKylC4R5VY/Tu63sLSU3nl/Jdrc60mWyzJTrpN3/s699wWrVzd1x/Hc741yq2o3KHuFYGZrzOwJM3vWzJ4xsy9U21ea2eNm9kL174rmwwXQpDofGU5IusndL5L0y5I+b2YXSbpF0k53v1DSzupnAItYNiG4+5S7P109Pippv6RzJF0taVv1tG2SrmkqSADDcUpfKprZOkmXSnpS0ip3n6qaXpO0aqCRARi62gnBzEYlPSzpRnd/c36b975hWfBbFjPbYmYTZjYxPXO8KFgAzaqVEMxsmXrJ4AF3f6TafMjMVlftqyUdXqivu29193F3Hx8bXT6ImAE0pE6VwSTdK2m/u981r2mHpM3V482SHh18eACGqc44hE9K+qykvWa2u9p2q6Q7JD1kZtdJekXSxmZCrKHkbroF066zU01LpmwnZO8eXLDked/TlAvORbZv6s7R/S4bLxVNBc+OQUk1FtztOvt6Y+eq5jCfbEJw928ndndFvcMAWAwYugwgICEACEgIAAISAoCAhAAgGO70Z1e85JIrp6TaC6axZu9aXFIeTE27zk1xTR03N3U6VbbKTVNOxdXQ6sdFU8Fz733i9yZbvk28B8nSbo19pzv3P+3aYuej5q8xVwgAAhICgICEACAgIQAISAgAAhICgICEACAY7jgEU7TGmrubbqrenL0Tb5/7lTJ34s30LVqGPVWLzo1hKBkvkJry29RU44J4U++PVONcpfZdMH4lpWhsS5/jZrzmQASuEAAEJAQAAQkBQEBCABCQEAAEJAQAwVDLjiaLlq5K7sKcK6gkSzW5KbAl5c7TTovv9+23030T7PQzku3+9lvxttRdmFVWZk3vuJkyXfY9SK1wnOubunN0ZvpzUkHZMbtqdiTmuqV5rhAABCQEAAEJAUBAQgAQkBAABCQEAAEJAUCQHYdgZmsk3S9plXol/63u/hUzu13S5yS9Xj31Vnd/rO9IcnXdzN12U5J17JJpyLmxBKkxDIkxClJmvMBcwXiAhqYwZ5c0T5wLz/S1ZanxHPExF5KKXm9y+vppp6f7vvU/8b6537nU8v3Hj/fV1+fqjX2o81d2QtJN7v60mZ0l6Skze7xq+7K7f6nWkQB0Xp3bwU9JmqoeHzWz/ZLOaTowAMN3StdTZrZO0qWSnqw23WBme8zsPjNbMeDYAAxZ7YRgZqOSHpZ0o7u/KeluSRdIWq/eFcSdkX5bzGzCzCZen/nxAEIG0JRaCcHMlqmXDB5w90ckyd0Pufusu89JukfSZQv1dfet7j7u7uMfHf3QoOIG0IBsQrDeNKl7Je1397vmbV8972nXSto3+PAADFOdKsMnJX1W0l4z211tu1XSJjNbr14pclLS9dk9mUkjC0+vzU3OLJoCmyg9lUxjbXIactLSzNv2/PPRptkfzSS7jlz16Xjj7qeiTX70aDqmtWujTXbJLyW7+t74cfWDH6SP+6H4Vamd/1PJrnO7/jXeuPon0sdNOPadvcn2M3/jymibfWQ0vfPI73PdO2zXqTJ8Wwv/vfY/5gBAJzFSEUBAQgAQkBAABCQEAAEJAUBAQgAQDPfuz0uWSKNnLdz2kY+l+37vP+JtZ5+d7HrgqzuibWv/PbFfSbNPfCPa5nsS9XFJcy/9V7RtyQXnJ/ta4jX50TfTfX/u4mjbyDv9L/+emqJul6xP9/35BQeySpJe+b2bkl3X3rw5HtK+/cm+I+OXRtuevfWvkn3PvyQ+1uCMn/npZF9be0G07bQX/zvZVxePR5smr/uDZNd1N21K7zuDKwQAAQkBQEBCABCQEAAEJAQAAQkBQDDcsuPpZ0hrL1ywyVbFp8dKko5MR5v8+08nu577h5+Lts1NvZTsa+fEy0c6dDDZd+m6eF+fTB/XZxLTlN94I9lXiWm9/uJz6b6Tk9Gm2ekfRttGPp6eRu7f+Zdo29rfT5fK/OUX4m2zmdWEV3402vSzv7sh2dV+Mr50qL+aKR2ujL9HI+elp04f/5M7om3nXnZe+ri/8ImFty9/MN2vwhUCgICEACAgIQAISAgAAhICgICEACAgIQAIhjsO4fgxad/Egk0+m65jn9i5M9o2sum308d9M14/95f2pPsenkoElVnCfU18HIKtXpPuO/VqtMm/t/A5DI4dix/33PR4D08sa759e/xc7f27dEzXjsWnc+85lr6j8eYn/jbaNvLw/cm+OhYfz/HW9+PL1UvS6R/+cLTtwDefjLZJ0t8894/Rtj/66o3Jvl/803+Itt180epomyTtvGLhqeLTP/5Rst+7uEIAEJAQAAQkBAABCQFAQEIAEJAQAASWuqvywA9m9rqkV+ZtGpMUn9fcDmKqh5jq60Jca909Phe8MtSE8L6Dm024e3zN6RYQUz3EVF9X41oIHxkABCQEAEHbCWFry8dfCDHVQ0z1dTWu92n1OwQA3dL2FQKADiEhAAhICAACEgKAgIQAIPhfYHOWbSs7YnoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#plots as nxn array of the original\n",
    "plt.matshow(b, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_kernel",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
